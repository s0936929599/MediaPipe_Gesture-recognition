{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfcd26e9-24d9-476a-98c3-c2fe5a9c96e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_hands = mp.solutions.hands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7fdc4b4b-6af5-499e-b7cb-b96bb6df4cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "gesture=[]\n",
    "cap = cv2.VideoCapture(0)\n",
    "i=1\n",
    "\n",
    "arr=np.zeros((1000,21*3), float)\n",
    "\n",
    "with mp_hands.Hands(\n",
    "    min_detection_confidence=0.7,\n",
    "    min_tracking_confidence=0.5) as hands:    \n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            print(\"Ignoring empty camera frame.\")\n",
    "          # If loading a video, use 'break' instead of 'continue'.\n",
    "            continue\n",
    "\n",
    "        # Flip the image horizontally for a later selfie-view display, and convert\n",
    "        # the BGR image to RGB.\n",
    "        image = cv2.cvtColor(cv2.flip(image, 1), cv2.COLOR_BGR2RGB)\n",
    "        # To improve performance, optionally mark the image as not writeable to\n",
    "        # pass by reference.\n",
    "        image.flags.writeable = False\n",
    "        results = hands.process(image)\n",
    "        \n",
    "        # Draw the hand annotations on the image.\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        if results.multi_hand_landmarks and i<=1000:\n",
    "            #gesture.append(results.multi_hand_landmarks)\n",
    "            j=0\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                mp_drawing.draw_landmarks(\n",
    "                  image, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "            for hand in hand_landmarks.landmark:\n",
    "                arr[i-1][j]=hand.x\n",
    "                arr[i-1][j+1]=hand.y\n",
    "                arr[i-1][j+2]=hand.z\n",
    "            \n",
    "                j+=3\n",
    "            i+=1\n",
    "        if i%100==0:\n",
    "            print(i)\n",
    "        cv2.imshow('MediaPipe Hands', image)\n",
    "        if cv2.waitKey(5) & 0xFF == 27:\n",
    "            cv2.destroyAllWindows()\n",
    "            break\n",
    "    cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49efd3b1-baf1-4665-be12-f29b215cc3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "open_hand=pd.DataFrame(arr)\n",
    "\n",
    "open_hand['label']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "448fdb98-c199-4058-b13e-3a7751fd96e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "close_hand=pd.DataFrame(arr)\n",
    "close_hand['label']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d10434e0-7993-47a5-86b7-50f6be882ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hand=pd.DataFrame(arr)\n",
    "y_hand['label']=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d59cd28c-8343-4e81-84ac-7050be530480",
   "metadata": {},
   "outputs": [],
   "source": [
    "hand=pd.concat([open_hand,close_hand,y_hand])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3fc67f68-e376-489a-8fec-dfa107f1a5ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.833149</td>\n",
       "      <td>0.629496</td>\n",
       "      <td>-0.000024</td>\n",
       "      <td>0.928025</td>\n",
       "      <td>0.622832</td>\n",
       "      <td>-0.130303</td>\n",
       "      <td>0.991587</td>\n",
       "      <td>0.552794</td>\n",
       "      <td>-0.212108</td>\n",
       "      <td>1.004466</td>\n",
       "      <td>...</td>\n",
       "      <td>0.769334</td>\n",
       "      <td>0.279096</td>\n",
       "      <td>-0.226989</td>\n",
       "      <td>0.772488</td>\n",
       "      <td>0.204773</td>\n",
       "      <td>-0.277028</td>\n",
       "      <td>0.781493</td>\n",
       "      <td>0.135246</td>\n",
       "      <td>-0.322072</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.812772</td>\n",
       "      <td>0.645777</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.907174</td>\n",
       "      <td>0.614594</td>\n",
       "      <td>-0.062439</td>\n",
       "      <td>0.987314</td>\n",
       "      <td>0.523253</td>\n",
       "      <td>-0.110714</td>\n",
       "      <td>1.049300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.732066</td>\n",
       "      <td>0.285229</td>\n",
       "      <td>-0.258613</td>\n",
       "      <td>0.732213</td>\n",
       "      <td>0.214447</td>\n",
       "      <td>-0.309217</td>\n",
       "      <td>0.742403</td>\n",
       "      <td>0.144799</td>\n",
       "      <td>-0.343637</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.782765</td>\n",
       "      <td>0.642106</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.879202</td>\n",
       "      <td>0.620290</td>\n",
       "      <td>-0.054581</td>\n",
       "      <td>0.955461</td>\n",
       "      <td>0.527797</td>\n",
       "      <td>-0.090177</td>\n",
       "      <td>1.008895</td>\n",
       "      <td>...</td>\n",
       "      <td>0.702938</td>\n",
       "      <td>0.281967</td>\n",
       "      <td>-0.266272</td>\n",
       "      <td>0.702177</td>\n",
       "      <td>0.210661</td>\n",
       "      <td>-0.317521</td>\n",
       "      <td>0.707997</td>\n",
       "      <td>0.136707</td>\n",
       "      <td>-0.360833</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.755722</td>\n",
       "      <td>0.647723</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>0.851797</td>\n",
       "      <td>0.617696</td>\n",
       "      <td>-0.052391</td>\n",
       "      <td>0.933352</td>\n",
       "      <td>0.517109</td>\n",
       "      <td>-0.084657</td>\n",
       "      <td>0.990319</td>\n",
       "      <td>...</td>\n",
       "      <td>0.673005</td>\n",
       "      <td>0.278001</td>\n",
       "      <td>-0.247867</td>\n",
       "      <td>0.670411</td>\n",
       "      <td>0.207971</td>\n",
       "      <td>-0.296648</td>\n",
       "      <td>0.673885</td>\n",
       "      <td>0.137356</td>\n",
       "      <td>-0.336731</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.731653</td>\n",
       "      <td>0.654872</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.827124</td>\n",
       "      <td>0.618203</td>\n",
       "      <td>-0.058439</td>\n",
       "      <td>0.910569</td>\n",
       "      <td>0.514562</td>\n",
       "      <td>-0.094062</td>\n",
       "      <td>0.968542</td>\n",
       "      <td>...</td>\n",
       "      <td>0.645745</td>\n",
       "      <td>0.277704</td>\n",
       "      <td>-0.235515</td>\n",
       "      <td>0.642503</td>\n",
       "      <td>0.208041</td>\n",
       "      <td>-0.282170</td>\n",
       "      <td>0.645512</td>\n",
       "      <td>0.137866</td>\n",
       "      <td>-0.323370</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.458610</td>\n",
       "      <td>0.704571</td>\n",
       "      <td>-0.000052</td>\n",
       "      <td>0.487046</td>\n",
       "      <td>0.648682</td>\n",
       "      <td>-0.084026</td>\n",
       "      <td>0.480158</td>\n",
       "      <td>0.565200</td>\n",
       "      <td>-0.127496</td>\n",
       "      <td>0.422133</td>\n",
       "      <td>...</td>\n",
       "      <td>0.334878</td>\n",
       "      <td>0.464115</td>\n",
       "      <td>-0.097190</td>\n",
       "      <td>0.346079</td>\n",
       "      <td>0.495083</td>\n",
       "      <td>-0.127618</td>\n",
       "      <td>0.361860</td>\n",
       "      <td>0.535190</td>\n",
       "      <td>-0.135674</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.458047</td>\n",
       "      <td>0.705080</td>\n",
       "      <td>-0.000048</td>\n",
       "      <td>0.485703</td>\n",
       "      <td>0.648050</td>\n",
       "      <td>-0.083753</td>\n",
       "      <td>0.477119</td>\n",
       "      <td>0.564987</td>\n",
       "      <td>-0.127873</td>\n",
       "      <td>0.418562</td>\n",
       "      <td>...</td>\n",
       "      <td>0.331907</td>\n",
       "      <td>0.466238</td>\n",
       "      <td>-0.095059</td>\n",
       "      <td>0.342442</td>\n",
       "      <td>0.496494</td>\n",
       "      <td>-0.126500</td>\n",
       "      <td>0.358033</td>\n",
       "      <td>0.536465</td>\n",
       "      <td>-0.135026</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.453861</td>\n",
       "      <td>0.705784</td>\n",
       "      <td>-0.000040</td>\n",
       "      <td>0.482129</td>\n",
       "      <td>0.649498</td>\n",
       "      <td>-0.084269</td>\n",
       "      <td>0.474921</td>\n",
       "      <td>0.566270</td>\n",
       "      <td>-0.127004</td>\n",
       "      <td>0.415625</td>\n",
       "      <td>...</td>\n",
       "      <td>0.329406</td>\n",
       "      <td>0.468226</td>\n",
       "      <td>-0.093980</td>\n",
       "      <td>0.337914</td>\n",
       "      <td>0.497487</td>\n",
       "      <td>-0.127724</td>\n",
       "      <td>0.352922</td>\n",
       "      <td>0.537396</td>\n",
       "      <td>-0.138676</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.452441</td>\n",
       "      <td>0.704912</td>\n",
       "      <td>-0.000044</td>\n",
       "      <td>0.480220</td>\n",
       "      <td>0.650073</td>\n",
       "      <td>-0.085705</td>\n",
       "      <td>0.471780</td>\n",
       "      <td>0.567123</td>\n",
       "      <td>-0.128492</td>\n",
       "      <td>0.411585</td>\n",
       "      <td>...</td>\n",
       "      <td>0.324834</td>\n",
       "      <td>0.469115</td>\n",
       "      <td>-0.088460</td>\n",
       "      <td>0.333175</td>\n",
       "      <td>0.500004</td>\n",
       "      <td>-0.121228</td>\n",
       "      <td>0.348757</td>\n",
       "      <td>0.540659</td>\n",
       "      <td>-0.131438</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.449159</td>\n",
       "      <td>0.708730</td>\n",
       "      <td>-0.000054</td>\n",
       "      <td>0.477251</td>\n",
       "      <td>0.653036</td>\n",
       "      <td>-0.085677</td>\n",
       "      <td>0.469176</td>\n",
       "      <td>0.569532</td>\n",
       "      <td>-0.128539</td>\n",
       "      <td>0.408259</td>\n",
       "      <td>...</td>\n",
       "      <td>0.321744</td>\n",
       "      <td>0.471636</td>\n",
       "      <td>-0.090214</td>\n",
       "      <td>0.328966</td>\n",
       "      <td>0.501115</td>\n",
       "      <td>-0.122697</td>\n",
       "      <td>0.344181</td>\n",
       "      <td>0.541169</td>\n",
       "      <td>-0.133032</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "0    0.833149  0.629496 -0.000024  0.928025  0.622832 -0.130303  0.991587   \n",
       "1    0.812772  0.645777  0.000026  0.907174  0.614594 -0.062439  0.987314   \n",
       "2    0.782765  0.642106  0.000022  0.879202  0.620290 -0.054581  0.955461   \n",
       "3    0.755722  0.647723 -0.000010  0.851797  0.617696 -0.052391  0.933352   \n",
       "4    0.731653  0.654872  0.000022  0.827124  0.618203 -0.058439  0.910569   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "995  0.458610  0.704571 -0.000052  0.487046  0.648682 -0.084026  0.480158   \n",
       "996  0.458047  0.705080 -0.000048  0.485703  0.648050 -0.083753  0.477119   \n",
       "997  0.453861  0.705784 -0.000040  0.482129  0.649498 -0.084269  0.474921   \n",
       "998  0.452441  0.704912 -0.000044  0.480220  0.650073 -0.085705  0.471780   \n",
       "999  0.449159  0.708730 -0.000054  0.477251  0.653036 -0.085677  0.469176   \n",
       "\n",
       "            7         8         9  ...        54        55        56  \\\n",
       "0    0.552794 -0.212108  1.004466  ...  0.769334  0.279096 -0.226989   \n",
       "1    0.523253 -0.110714  1.049300  ...  0.732066  0.285229 -0.258613   \n",
       "2    0.527797 -0.090177  1.008895  ...  0.702938  0.281967 -0.266272   \n",
       "3    0.517109 -0.084657  0.990319  ...  0.673005  0.278001 -0.247867   \n",
       "4    0.514562 -0.094062  0.968542  ...  0.645745  0.277704 -0.235515   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "995  0.565200 -0.127496  0.422133  ...  0.334878  0.464115 -0.097190   \n",
       "996  0.564987 -0.127873  0.418562  ...  0.331907  0.466238 -0.095059   \n",
       "997  0.566270 -0.127004  0.415625  ...  0.329406  0.468226 -0.093980   \n",
       "998  0.567123 -0.128492  0.411585  ...  0.324834  0.469115 -0.088460   \n",
       "999  0.569532 -0.128539  0.408259  ...  0.321744  0.471636 -0.090214   \n",
       "\n",
       "           57        58        59        60        61        62  label  \n",
       "0    0.772488  0.204773 -0.277028  0.781493  0.135246 -0.322072      0  \n",
       "1    0.732213  0.214447 -0.309217  0.742403  0.144799 -0.343637      0  \n",
       "2    0.702177  0.210661 -0.317521  0.707997  0.136707 -0.360833      0  \n",
       "3    0.670411  0.207971 -0.296648  0.673885  0.137356 -0.336731      0  \n",
       "4    0.642503  0.208041 -0.282170  0.645512  0.137866 -0.323370      0  \n",
       "..        ...       ...       ...       ...       ...       ...    ...  \n",
       "995  0.346079  0.495083 -0.127618  0.361860  0.535190 -0.135674      2  \n",
       "996  0.342442  0.496494 -0.126500  0.358033  0.536465 -0.135026      2  \n",
       "997  0.337914  0.497487 -0.127724  0.352922  0.537396 -0.138676      2  \n",
       "998  0.333175  0.500004 -0.121228  0.348757  0.540659 -0.131438      2  \n",
       "999  0.328966  0.501115 -0.122697  0.344181  0.541169 -0.133032      2  \n",
       "\n",
       "[3000 rows x 64 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8bcf79cb-0f8e-4f48-81a7-5d9d7e0f60ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "hand.to_csv('/home/ax/下載/hand.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10a2eaca-6cb6-4d2c-ad75-05db5e26aea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "hand=pd.read_csv('/home/ax/下載/hand.csv')\n",
    "hand=hand.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "613fa0ad-d277-4290-94aa-da12bf11670f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.833149</td>\n",
       "      <td>0.629496</td>\n",
       "      <td>-0.000024</td>\n",
       "      <td>0.928025</td>\n",
       "      <td>0.622832</td>\n",
       "      <td>-0.130303</td>\n",
       "      <td>0.991587</td>\n",
       "      <td>0.552794</td>\n",
       "      <td>-0.212108</td>\n",
       "      <td>1.004466</td>\n",
       "      <td>...</td>\n",
       "      <td>0.769334</td>\n",
       "      <td>0.279096</td>\n",
       "      <td>-0.226989</td>\n",
       "      <td>0.772488</td>\n",
       "      <td>0.204773</td>\n",
       "      <td>-0.277028</td>\n",
       "      <td>0.781493</td>\n",
       "      <td>0.135246</td>\n",
       "      <td>-0.322072</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.812772</td>\n",
       "      <td>0.645777</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.907174</td>\n",
       "      <td>0.614594</td>\n",
       "      <td>-0.062439</td>\n",
       "      <td>0.987314</td>\n",
       "      <td>0.523253</td>\n",
       "      <td>-0.110714</td>\n",
       "      <td>1.049300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.732066</td>\n",
       "      <td>0.285229</td>\n",
       "      <td>-0.258613</td>\n",
       "      <td>0.732213</td>\n",
       "      <td>0.214447</td>\n",
       "      <td>-0.309217</td>\n",
       "      <td>0.742403</td>\n",
       "      <td>0.144799</td>\n",
       "      <td>-0.343637</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.782765</td>\n",
       "      <td>0.642106</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.879202</td>\n",
       "      <td>0.620290</td>\n",
       "      <td>-0.054581</td>\n",
       "      <td>0.955461</td>\n",
       "      <td>0.527797</td>\n",
       "      <td>-0.090177</td>\n",
       "      <td>1.008895</td>\n",
       "      <td>...</td>\n",
       "      <td>0.702938</td>\n",
       "      <td>0.281967</td>\n",
       "      <td>-0.266272</td>\n",
       "      <td>0.702177</td>\n",
       "      <td>0.210661</td>\n",
       "      <td>-0.317521</td>\n",
       "      <td>0.707997</td>\n",
       "      <td>0.136707</td>\n",
       "      <td>-0.360833</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.755722</td>\n",
       "      <td>0.647723</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>0.851797</td>\n",
       "      <td>0.617696</td>\n",
       "      <td>-0.052391</td>\n",
       "      <td>0.933352</td>\n",
       "      <td>0.517109</td>\n",
       "      <td>-0.084657</td>\n",
       "      <td>0.990319</td>\n",
       "      <td>...</td>\n",
       "      <td>0.673005</td>\n",
       "      <td>0.278001</td>\n",
       "      <td>-0.247867</td>\n",
       "      <td>0.670411</td>\n",
       "      <td>0.207971</td>\n",
       "      <td>-0.296648</td>\n",
       "      <td>0.673885</td>\n",
       "      <td>0.137356</td>\n",
       "      <td>-0.336731</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.731653</td>\n",
       "      <td>0.654872</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.827124</td>\n",
       "      <td>0.618203</td>\n",
       "      <td>-0.058439</td>\n",
       "      <td>0.910569</td>\n",
       "      <td>0.514562</td>\n",
       "      <td>-0.094062</td>\n",
       "      <td>0.968542</td>\n",
       "      <td>...</td>\n",
       "      <td>0.645745</td>\n",
       "      <td>0.277704</td>\n",
       "      <td>-0.235515</td>\n",
       "      <td>0.642503</td>\n",
       "      <td>0.208041</td>\n",
       "      <td>-0.282170</td>\n",
       "      <td>0.645512</td>\n",
       "      <td>0.137866</td>\n",
       "      <td>-0.323370</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>0.458610</td>\n",
       "      <td>0.704571</td>\n",
       "      <td>-0.000052</td>\n",
       "      <td>0.487046</td>\n",
       "      <td>0.648682</td>\n",
       "      <td>-0.084026</td>\n",
       "      <td>0.480158</td>\n",
       "      <td>0.565200</td>\n",
       "      <td>-0.127496</td>\n",
       "      <td>0.422133</td>\n",
       "      <td>...</td>\n",
       "      <td>0.334878</td>\n",
       "      <td>0.464115</td>\n",
       "      <td>-0.097190</td>\n",
       "      <td>0.346079</td>\n",
       "      <td>0.495083</td>\n",
       "      <td>-0.127618</td>\n",
       "      <td>0.361860</td>\n",
       "      <td>0.535190</td>\n",
       "      <td>-0.135674</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>0.458047</td>\n",
       "      <td>0.705080</td>\n",
       "      <td>-0.000048</td>\n",
       "      <td>0.485703</td>\n",
       "      <td>0.648050</td>\n",
       "      <td>-0.083753</td>\n",
       "      <td>0.477119</td>\n",
       "      <td>0.564987</td>\n",
       "      <td>-0.127873</td>\n",
       "      <td>0.418562</td>\n",
       "      <td>...</td>\n",
       "      <td>0.331907</td>\n",
       "      <td>0.466238</td>\n",
       "      <td>-0.095059</td>\n",
       "      <td>0.342442</td>\n",
       "      <td>0.496494</td>\n",
       "      <td>-0.126500</td>\n",
       "      <td>0.358033</td>\n",
       "      <td>0.536465</td>\n",
       "      <td>-0.135026</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>0.453861</td>\n",
       "      <td>0.705784</td>\n",
       "      <td>-0.000040</td>\n",
       "      <td>0.482129</td>\n",
       "      <td>0.649498</td>\n",
       "      <td>-0.084269</td>\n",
       "      <td>0.474921</td>\n",
       "      <td>0.566270</td>\n",
       "      <td>-0.127004</td>\n",
       "      <td>0.415625</td>\n",
       "      <td>...</td>\n",
       "      <td>0.329406</td>\n",
       "      <td>0.468226</td>\n",
       "      <td>-0.093980</td>\n",
       "      <td>0.337914</td>\n",
       "      <td>0.497487</td>\n",
       "      <td>-0.127724</td>\n",
       "      <td>0.352922</td>\n",
       "      <td>0.537396</td>\n",
       "      <td>-0.138676</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>0.452441</td>\n",
       "      <td>0.704912</td>\n",
       "      <td>-0.000044</td>\n",
       "      <td>0.480220</td>\n",
       "      <td>0.650073</td>\n",
       "      <td>-0.085705</td>\n",
       "      <td>0.471780</td>\n",
       "      <td>0.567123</td>\n",
       "      <td>-0.128492</td>\n",
       "      <td>0.411585</td>\n",
       "      <td>...</td>\n",
       "      <td>0.324834</td>\n",
       "      <td>0.469115</td>\n",
       "      <td>-0.088460</td>\n",
       "      <td>0.333175</td>\n",
       "      <td>0.500004</td>\n",
       "      <td>-0.121228</td>\n",
       "      <td>0.348757</td>\n",
       "      <td>0.540659</td>\n",
       "      <td>-0.131438</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>0.449159</td>\n",
       "      <td>0.708730</td>\n",
       "      <td>-0.000054</td>\n",
       "      <td>0.477251</td>\n",
       "      <td>0.653036</td>\n",
       "      <td>-0.085677</td>\n",
       "      <td>0.469176</td>\n",
       "      <td>0.569532</td>\n",
       "      <td>-0.128539</td>\n",
       "      <td>0.408259</td>\n",
       "      <td>...</td>\n",
       "      <td>0.321744</td>\n",
       "      <td>0.471636</td>\n",
       "      <td>-0.090214</td>\n",
       "      <td>0.328966</td>\n",
       "      <td>0.501115</td>\n",
       "      <td>-0.122697</td>\n",
       "      <td>0.344181</td>\n",
       "      <td>0.541169</td>\n",
       "      <td>-0.133032</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6  \\\n",
       "0     0.833149  0.629496 -0.000024  0.928025  0.622832 -0.130303  0.991587   \n",
       "1     0.812772  0.645777  0.000026  0.907174  0.614594 -0.062439  0.987314   \n",
       "2     0.782765  0.642106  0.000022  0.879202  0.620290 -0.054581  0.955461   \n",
       "3     0.755722  0.647723 -0.000010  0.851797  0.617696 -0.052391  0.933352   \n",
       "4     0.731653  0.654872  0.000022  0.827124  0.618203 -0.058439  0.910569   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "2995  0.458610  0.704571 -0.000052  0.487046  0.648682 -0.084026  0.480158   \n",
       "2996  0.458047  0.705080 -0.000048  0.485703  0.648050 -0.083753  0.477119   \n",
       "2997  0.453861  0.705784 -0.000040  0.482129  0.649498 -0.084269  0.474921   \n",
       "2998  0.452441  0.704912 -0.000044  0.480220  0.650073 -0.085705  0.471780   \n",
       "2999  0.449159  0.708730 -0.000054  0.477251  0.653036 -0.085677  0.469176   \n",
       "\n",
       "             7         8         9  ...        54        55        56  \\\n",
       "0     0.552794 -0.212108  1.004466  ...  0.769334  0.279096 -0.226989   \n",
       "1     0.523253 -0.110714  1.049300  ...  0.732066  0.285229 -0.258613   \n",
       "2     0.527797 -0.090177  1.008895  ...  0.702938  0.281967 -0.266272   \n",
       "3     0.517109 -0.084657  0.990319  ...  0.673005  0.278001 -0.247867   \n",
       "4     0.514562 -0.094062  0.968542  ...  0.645745  0.277704 -0.235515   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "2995  0.565200 -0.127496  0.422133  ...  0.334878  0.464115 -0.097190   \n",
       "2996  0.564987 -0.127873  0.418562  ...  0.331907  0.466238 -0.095059   \n",
       "2997  0.566270 -0.127004  0.415625  ...  0.329406  0.468226 -0.093980   \n",
       "2998  0.567123 -0.128492  0.411585  ...  0.324834  0.469115 -0.088460   \n",
       "2999  0.569532 -0.128539  0.408259  ...  0.321744  0.471636 -0.090214   \n",
       "\n",
       "            57        58        59        60        61        62  label  \n",
       "0     0.772488  0.204773 -0.277028  0.781493  0.135246 -0.322072      0  \n",
       "1     0.732213  0.214447 -0.309217  0.742403  0.144799 -0.343637      0  \n",
       "2     0.702177  0.210661 -0.317521  0.707997  0.136707 -0.360833      0  \n",
       "3     0.670411  0.207971 -0.296648  0.673885  0.137356 -0.336731      0  \n",
       "4     0.642503  0.208041 -0.282170  0.645512  0.137866 -0.323370      0  \n",
       "...        ...       ...       ...       ...       ...       ...    ...  \n",
       "2995  0.346079  0.495083 -0.127618  0.361860  0.535190 -0.135674      2  \n",
       "2996  0.342442  0.496494 -0.126500  0.358033  0.536465 -0.135026      2  \n",
       "2997  0.337914  0.497487 -0.127724  0.352922  0.537396 -0.138676      2  \n",
       "2998  0.333175  0.500004 -0.121228  0.348757  0.540659 -0.131438      2  \n",
       "2999  0.328966  0.501115 -0.122697  0.344181  0.541169 -0.133032      2  \n",
       "\n",
       "[3000 rows x 64 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf995ebd-9e19-4ba5-a41c-73300340967a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images=np.array(hand.iloc[:,0:-1])\n",
    "train_labels=np.array(hand.iloc[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e133f365-1b31-4f91-ac43-5950e3d704d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_images, train_labels, train_size=0.75, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e236ac4e-ee91-49d6-b4f8-a4649f8a5154",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels=tf.one_hot(np.array(hand.iloc[:,-1]),depth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd2482e3-e23b-46c2-abc9-eb05dd2cf936",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "\n",
    "clf = clf.fit(train_images, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84bc9984-c9e7-4763-b967-a2ea986adc99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(train_images[105:168][:].reshape(-1,63))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25ecaed9-0969-47a0-a024-806f313deefc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 128)               8192      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 16,643\n",
      "Trainable params: 16,643\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input((21 * 3, )),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13c1e1d8-fda6-4e19-92bb-e32593d2782f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d697e8b-3339-474a-910a-4ec374dd613e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "18/18 [==============================] - 1s 9ms/step - loss: 0.9774 - accuracy: 0.6040 - val_loss: 0.7786 - val_accuracy: 0.9333\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6753 - accuracy: 0.8893 - val_loss: 0.4369 - val_accuracy: 0.9533\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3729 - accuracy: 0.9453 - val_loss: 0.1825 - val_accuracy: 0.9827\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1748 - accuracy: 0.9747 - val_loss: 0.0774 - val_accuracy: 0.9907\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0908 - accuracy: 0.9867 - val_loss: 0.0394 - val_accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0564 - accuracy: 0.9951 - val_loss: 0.0239 - val_accuracy: 1.0000\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0356 - accuracy: 0.9987 - val_loss: 0.0156 - val_accuracy: 1.0000\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0252 - accuracy: 0.9987 - val_loss: 0.0108 - val_accuracy: 1.0000\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0205 - accuracy: 0.9991 - val_loss: 0.0089 - val_accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0150 - accuracy: 0.9991 - val_loss: 0.0064 - val_accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0140 - accuracy: 0.9987 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0086 - accuracy: 0.9996 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0098 - accuracy: 0.9987 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0059 - accuracy: 0.9996 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0054 - accuracy: 0.9991 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0063 - accuracy: 0.9991 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0031 - accuracy: 0.9996 - val_loss: 8.8014e-04 - val_accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 8.0259e-04 - val_accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 6.9238e-04 - val_accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0030 - accuracy: 0.9996 - val_loss: 8.7949e-04 - val_accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 5.9319e-04 - val_accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 5.2989e-04 - val_accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 6.1763e-04 - val_accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 5.2334e-04 - val_accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 0.9996 - val_loss: 6.4649e-04 - val_accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 4.6428e-04 - val_accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 5.5207e-04 - val_accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 3.9983e-04 - val_accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 3.4189e-04 - val_accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 3.2177e-04 - val_accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 2.9324e-04 - val_accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 7.7273e-04 - accuracy: 1.0000 - val_loss: 2.6377e-04 - val_accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9.2482e-04 - accuracy: 1.0000 - val_loss: 2.6180e-04 - val_accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 7.7852e-04 - accuracy: 1.0000 - val_loss: 2.4117e-04 - val_accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 7.0878e-04 - accuracy: 1.0000 - val_loss: 2.1055e-04 - val_accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 6.6818e-04 - accuracy: 1.0000 - val_loss: 1.9052e-04 - val_accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 6.7167e-04 - accuracy: 1.0000 - val_loss: 1.9259e-04 - val_accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 7.3476e-04 - accuracy: 1.0000 - val_loss: 1.9699e-04 - val_accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 7.6392e-04 - accuracy: 1.0000 - val_loss: 1.7791e-04 - val_accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 6.8088e-04 - accuracy: 1.0000 - val_loss: 1.6155e-04 - val_accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9.1475e-04 - accuracy: 0.9996 - val_loss: 2.2677e-04 - val_accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9.2967e-04 - accuracy: 1.0000 - val_loss: 2.0325e-04 - val_accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 8.0316e-04 - accuracy: 1.0000 - val_loss: 1.6581e-04 - val_accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 7.3470e-04 - accuracy: 1.0000 - val_loss: 1.4571e-04 - val_accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 5.7281e-04 - accuracy: 1.0000 - val_loss: 1.2599e-04 - val_accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 5.3711e-04 - accuracy: 1.0000 - val_loss: 1.2082e-04 - val_accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 5.0968e-04 - accuracy: 1.0000 - val_loss: 1.0330e-04 - val_accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.3176e-04 - accuracy: 1.0000 - val_loss: 1.0397e-04 - val_accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 3.9157e-04 - accuracy: 1.0000 - val_loss: 1.0513e-04 - val_accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 3.4773e-04 - accuracy: 1.0000 - val_loss: 1.0263e-04 - val_accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 3.7850e-04 - accuracy: 1.0000 - val_loss: 9.1900e-05 - val_accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.2620e-04 - accuracy: 1.0000 - val_loss: 9.2222e-05 - val_accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.4324e-04 - accuracy: 1.0000 - val_loss: 8.6973e-05 - val_accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.1892e-04 - accuracy: 1.0000 - val_loss: 7.8785e-05 - val_accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 3.6124e-04 - accuracy: 1.0000 - val_loss: 7.5923e-05 - val_accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 3.0031e-04 - accuracy: 1.0000 - val_loss: 8.4171e-05 - val_accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.1942e-04 - accuracy: 1.0000 - val_loss: 9.4996e-05 - val_accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 3.2138e-04 - accuracy: 1.0000 - val_loss: 8.3571e-05 - val_accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 3.2384e-04 - accuracy: 1.0000 - val_loss: 7.7501e-05 - val_accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 2.5905e-04 - accuracy: 1.0000 - val_loss: 6.3652e-05 - val_accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 2.5132e-04 - accuracy: 1.0000 - val_loss: 5.9921e-05 - val_accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 5.2214e-04 - accuracy: 1.0000 - val_loss: 8.3743e-05 - val_accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.5542e-04 - accuracy: 1.0000 - val_loss: 9.2275e-05 - val_accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 4.8987e-04 - accuracy: 1.0000 - val_loss: 6.1895e-05 - val_accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 3.5891e-04 - accuracy: 1.0000 - val_loss: 7.0909e-05 - val_accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 2.8479e-04 - accuracy: 1.0000 - val_loss: 5.7538e-05 - val_accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 2.7027e-04 - accuracy: 1.0000 - val_loss: 5.4108e-05 - val_accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 3.5792e-04 - accuracy: 1.0000 - val_loss: 5.2929e-05 - val_accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 3.6981e-04 - accuracy: 1.0000 - val_loss: 8.8163e-05 - val_accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 3.6369e-04 - accuracy: 1.0000 - val_loss: 7.1096e-05 - val_accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 2.2666e-04 - accuracy: 1.0000 - val_loss: 5.5940e-05 - val_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.9900e-04 - accuracy: 1.0000 - val_loss: 4.5681e-05 - val_accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.7140e-04 - accuracy: 1.0000 - val_loss: 4.0769e-05 - val_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 3.5331e-04 - accuracy: 1.0000 - val_loss: 6.5393e-05 - val_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 5.4395e-04 - accuracy: 1.0000 - val_loss: 3.6377e-05 - val_accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 2.1442e-04 - accuracy: 1.0000 - val_loss: 3.9785e-05 - val_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 2.0938e-04 - accuracy: 1.0000 - val_loss: 3.5177e-05 - val_accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 2.3901e-04 - accuracy: 1.0000 - val_loss: 6.4499e-05 - val_accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.9688e-04 - accuracy: 1.0000 - val_loss: 5.0893e-05 - val_accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.7649e-04 - accuracy: 1.0000 - val_loss: 3.6437e-05 - val_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.5177e-04 - accuracy: 1.0000 - val_loss: 3.5249e-05 - val_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 2.4262e-04 - accuracy: 1.0000 - val_loss: 4.6959e-05 - val_accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.9121e-04 - accuracy: 1.0000 - val_loss: 5.8212e-05 - val_accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 2.2983e-04 - accuracy: 1.0000 - val_loss: 3.0134e-05 - val_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 2.6563e-04 - accuracy: 1.0000 - val_loss: 3.2119e-05 - val_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.2915e-04 - accuracy: 1.0000 - val_loss: 3.6810e-05 - val_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.5710e-04 - accuracy: 1.0000 - val_loss: 3.1669e-05 - val_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.4422e-04 - accuracy: 1.0000 - val_loss: 3.0094e-05 - val_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.4006e-04 - accuracy: 1.0000 - val_loss: 2.4500e-05 - val_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.9558e-04 - accuracy: 1.0000 - val_loss: 2.4074e-05 - val_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.0992e-04 - accuracy: 1.0000 - val_loss: 2.3194e-05 - val_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.4432e-04 - accuracy: 1.0000 - val_loss: 2.2001e-05 - val_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.1651e-04 - accuracy: 1.0000 - val_loss: 2.0700e-05 - val_accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.0949e-04 - accuracy: 1.0000 - val_loss: 2.0348e-05 - val_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9.3507e-05 - accuracy: 1.0000 - val_loss: 2.0029e-05 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8b0c1017c0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=100,\n",
    "    batch_size=128,\n",
    "    validation_data=(X_test, y_test)\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3cfffe3b-f7a1-4beb-963e-72c3c1101e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "\n",
    "with mp_hands.Hands(\n",
    "    min_detection_confidence=0.7,\n",
    "    min_tracking_confidence=0.5) as hands:    \n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            print(\"Ignoring empty camera frame.\")\n",
    "          # If loading a video, use 'break' instead of 'continue'.\n",
    "            continue\n",
    "\n",
    "        # Flip the image horizontally for a later selfie-view display, and convert\n",
    "        # the BGR image to RGB.\n",
    "        image = cv2.cvtColor(cv2.flip(image, 1), cv2.COLOR_BGR2RGB)\n",
    "        # To improve performance, optionally mark the image as not writeable to\n",
    "        # pass by reference.\n",
    "        image.flags.writeable = False\n",
    "        results = hands.process(image)\n",
    "        \n",
    "        # Draw the hand annotations on the image.\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        if results.multi_hand_landmarks:\n",
    "            #gesture.append(results.multi_hand_landmarks)\n",
    "          \n",
    "            data=[]\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                mp_drawing.draw_landmarks(\n",
    "                  image, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "            for hand in hand_landmarks.landmark:\n",
    "                data.append(hand.x)\n",
    "                data.append(hand.y)\n",
    "                data.append(hand.z)\n",
    "                \n",
    "            #ans=np.argmax(model.predict(np.array(data).reshape(-1,63)), axis=1)[0] #dnn model\n",
    "            ans=clf.predict(np.array(data).reshape(-1,63))[0] #decison tree \n",
    "            if ans==0:  \n",
    "                \n",
    "                text=\"Open\"\n",
    "                \n",
    "            elif ans==1:\n",
    "                \n",
    "                text=\"Close\"\n",
    "            else:\n",
    "                \n",
    "                text=\"YA\"\n",
    "                \n",
    "            cv2.putText(image, text, (50, 70), cv2.FONT_HERSHEY_TRIPLEX,\n",
    "              3, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "        cv2.imshow('MediaPipe Hands', image)\n",
    "        if cv2.waitKey(5) & 0xFF == 27:\n",
    "            cv2.destroyAllWindows()\n",
    "            break\n",
    "    cap.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
